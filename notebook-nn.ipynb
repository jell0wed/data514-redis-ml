{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redis as a high-performance machine learning database\n",
    "## NLP : Identifying toxic comments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research question:** can Redis serve as a real-time database for both training and testing purposes when training a neural network in production? How could we get Redis to act as the back-end database serving training examples when training our model.\n",
    "\n",
    "**IMPORTANT**: Make sure to have clone the repo, started a new Redis database instance locally before running this notebook. Refer to the `README.md` for further machine setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import redis\n",
    "from matplotlib import pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Neural Network implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redis is meant to be used in multiple ways and is basically a large-scale, distributed and high-performance key-value datastore. It also supports indexing and storage of JSON document, which we'll be using here to store both our **training** and **testing** datasets. \n",
    "\n",
    "According to our architecture, the `train:*` index prefix contains all the training example in JSON format and the `test:*` contains all the testing examples.\n",
    "\n",
    "Let's make sure the database is filled up and ready to go by checking the dbsize(). \n",
    "\n",
    "**If the number printed below is zero, make sure you ran the `notebook-dataprep.ipynb` notebook and the `python ./fill_db.py` command. Prior to executing this notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195279"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to local redis database\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "\n",
    "# checking to make sure every entries was inserted into database\n",
    "r.dbsize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the training and testing dataset into our Redis database, we'll define our neural network.\n",
    "\n",
    "**Initializing the embeddings and tokenizer**:\n",
    "\n",
    "We'll make sure of the `torchtext` python package which provides an out-of-the-box sentence tokenizer as well as the GloVe embedding. For this project, we decided to use the GloVe 840B embeddings of 300 dimensions for each words. Below we initialize both the tokenizer and the glove embeddings, running this cell might take some as it needs to fetch the embeddings remotely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "global_vectors = GloVe(name='840B', dim=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write our own torch `Dataset` and `DataLoader` definition to be used in conjunction with Pytorch. More specifically, this dataset and dataloader are going to query the Redis database to return both our testing and training data in real-time.\n",
    "\n",
    "The dataset takes care of returning elements in our database one-by-one in an iterator fashion. \n",
    "The dataloader takes in the `collate_fn` as a parameter which `vectorize_batch` is passed in in order to encode the comment text into GloVe embeddings.\n",
    "\n",
    "This way, Redis can act as the backend database for training the neural network using real time data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "import sys\n",
    "\n",
    "MAX_COMMENT_LENGTH = 50\n",
    "EMBED_LEN = 300\n",
    "NORMAL_CLASS = \"normal\"\n",
    "TARGET_CLASSES = [NORMAL_CLASS, \"toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "def get_target_class(obj, idx):\n",
    "    labels = {attr: obj[attr] for attr in TARGET_CLASSES}\n",
    "    return next((k for k, v in labels.items() if v == 1), None)\n",
    "\n",
    "class RedisDataset(Dataset):\n",
    "    def __init__(self, redis, redis_key_prefix):\n",
    "        self.redis = redis\n",
    "        self.scan_iter = self.redis.scan_iter(redis_key_prefix + \"*\")\n",
    "        self.length = len(self.redis.keys(redis_key_prefix + \"*\"))\n",
    "        self.curr_idx = 0\n",
    "        self.redis_key_prefix = redis_key_prefix\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length - 1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        key = self.redis_key_prefix + \"%d\" % idx\n",
    "        obj = r.json().get(key)\n",
    "        if obj is None:\n",
    "            print(\"obj none\", key)\n",
    "            raise IndexError()\n",
    "        label = get_target_class(obj, key)\n",
    "        return obj[\"comment_text\"], TARGET_CLASSES.index(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj none train:4003\n",
      "obj none test:17877\n",
      "training db dataset length is 4003\n",
      "testing db dataset length is 17877\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = RedisDataset(r, \"train:\"), RedisDataset(r, \"test:\")\n",
    "train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)\n",
    "print(\"training db dataset length is\", len(train_dataset))\n",
    "print(\"testing db dataset length is\", len(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We not create the pytorch DataLoader for our custom Redis-backed dataset. The `vectorize_batch` function takes care of tokenzing and embedding the `comment_text` into the GloVe embeddings up to a `MAX_LENGTH` and pads it with empty string to fit the length of 0 in the case where the comment text is too short. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "def vectorize_batch(batch):\n",
    "    X, Y = list(zip(*batch))\n",
    "    X = [tokenizer(x) for x in X]\n",
    "    X = [tokens+[\"\"] * (MAX_COMMENT_LENGTH-len(tokens)) if len(tokens) < MAX_COMMENT_LENGTH else tokens[:MAX_COMMENT_LENGTH] for tokens in X]\n",
    "    X_tensor = torch.zeros(len(batch), MAX_COMMENT_LENGTH, EMBED_LEN)\n",
    "    for i, tokens in enumerate(X):\n",
    "        X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
    "    return X_tensor.reshape(len(batch), -1), torch.tensor(Y)\n",
    "\n",
    "train_loader, test_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch), DataLoader(test_dataset, batch_size=1024, collate_fn=vectorize_batch)\n",
    "for X, Y in train_loader:\n",
    "    print(Y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define our `ToxicCommentClassifier` which is a simple Pytorch neural network. It consists of 4 linear layers of 256, 128, 64 and 6 output units. We use the ReLU activation function after each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ToxicCommentClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToxicCommentClassifier, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(MAX_COMMENT_LENGTH*EMBED_LEN, 256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(64, len(TARGET_CLASSES))\n",
    "        )\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        return self.seq(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_and_accuracy(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        Y_processed, Y_preds, losses = [],[],[]\n",
    "        for X, Y in val_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            Y_processed.append(Y)\n",
    "            Y_preds.append(preds.argmax(dim=-1))\n",
    "\n",
    "        Y_processed = torch.cat(Y_processed)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "        print(\"Validation loss\", torch.tensor(losses).mean())\n",
    "        print(\"Validation accuracy\", accuracy_score(Y_processed.detach().numpy(), Y_preds.detach().numpy()))\n",
    "        \n",
    "losses_graph = []\n",
    "def train_model(model, loss_fn, optimizer, train_loader, val_loader, epochs=25):\n",
    "    for i in range(1, epochs+1):\n",
    "        print(\"Epoch #%d\" % i)\n",
    "        losses = []\n",
    "        for X, Y in tqdm(train_loader): # for each batch\n",
    "            Y_preds = model(X) # execute model\n",
    "\n",
    "            loss = loss_fn(Y_preds, Y) # evaluate loss function\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # backward pass\n",
    "            optimizer.step()\n",
    "\n",
    "        losses_graph.append(torch.tensor(losses).mean())\n",
    "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.262\n",
      "Epoch #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.286\n",
      "Epoch #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.072\n",
      "Epoch #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.027\n",
      "Epoch #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.011\n",
      "Epoch #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.005\n",
      "Epoch #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.003\n",
      "Epoch #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.002\n",
      "Epoch #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.002\n",
      "Epoch #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n",
      "Epoch #25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "toxic_classifier = ToxicCommentClassifier()\n",
    "optimizer = Adam(toxic_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(toxic_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 1.0\n",
      "\n",
      "Confusion Matrix : \n",
      "[[4003]]\n"
     ]
    }
   ],
   "source": [
    "def do_prediction(model, loader):\n",
    "    Y_shuffled, Y_preds = [], []\n",
    "    for X, Y in loader:\n",
    "        preds = model(X)\n",
    "        Y_preds.append(preds)\n",
    "        Y_shuffled.append(Y)\n",
    "    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
    "\n",
    "    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
    "\n",
    "Y_actual, Y_preds = do_prediction(toxic_classifier, test_loader)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n",
    "print(\"\\nConfusion Matrix : \")\n",
    "print(confusion_matrix(Y_actual, Y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 1.2627e-20, 4.7383e-22, 3.8218e-23, 1.5374e-22, 1.5926e-19]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Predicting sentence `this project was great`: None\n",
      "tensor([[0.8821, 0.0245, 0.0189, 0.0174, 0.0204, 0.0367]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Predicting sentence `you are so bad you cant finish this project`: None\n"
     ]
    }
   ],
   "source": [
    "def do_prediction(model, text):\n",
    "    text_tokens = tokenizer(text)\n",
    "    text_tokens = text_tokens[:MAX_COMMENT_LENGTH]\n",
    "    X_tensor = torch.zeros(1, MAX_COMMENT_LENGTH, EMBED_LEN)\n",
    "    if len(text_tokens) < MAX_COMMENT_LENGTH:\n",
    "        text_tokens = text_tokens + ([\"\"] * (MAX_COMMENT_LENGTH - len(text_tokens)))\n",
    "    X_tensor[0] = global_vectors.get_vecs_by_tokens(text_tokens)\n",
    "    preds = model(X_tensor.reshape(1, -1))\n",
    "\n",
    "    print(F.softmax(preds, dim=-1))\n",
    "    #return TARGET_CLASSES[(preds.argmax(dim=-1).detach().numpy())[0]]\n",
    "\n",
    "print(\"Predicting sentence `this project was great`:\", do_prediction(toxic_classifier, \"this project was great!\"))\n",
    "print(\"Predicting sentence `you are so bad you cant finish this project`:\", do_prediction(toxic_classifier, \"fucking normie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "losses = list(map(lambda t: t.detach().item(), losses_graph))\n",
    "plt.plot(losses)\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the same `RedisDataset` to process unlabeled data in conjunction with Pytorch's DataLoader, similar to what we have done above for training and testing the model. Predictions are going to be stored at the same key for which it was returned.\n",
    "\n",
    "Each entry in the `unlabeled:` index will be retrieved, passed through the model, and moved to the `label:*` index with its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from redis.commands.json.path import Path\n",
    "test_example_0 = {\n",
    "    'id': \"jepoisso-0\",\n",
    "    'comment_text': \"i love this project\",\n",
    "    'toxic': 0,\n",
    "    'severe_toxic': 0,\n",
    "    'obscene': 0,\n",
    "    'threat': 0,\n",
    "    'insult': 0,\n",
    "    'identity_hate': 0\n",
    "}\n",
    "r.json().set(\"unlabeled:0\", Path.root_path(), test_example_0)\n",
    "\n",
    "test_example_1 = {\n",
    "    'id': \"jepoisso-1\",\n",
    "    'comment_text': \"you are dumb\",\n",
    "    'toxic': 0,\n",
    "    'severe_toxic': 0,\n",
    "    'obscene': 0,\n",
    "    'threat': 0,\n",
    "    'insult': 0,\n",
    "    'identity_hate': 0\n",
    "}\n",
    "r.json().set(\"unlabeled:1\", Path.root_path(), test_example_1)\n",
    "\n",
    "from redis.commands.json.path import Path\n",
    "test_example_2 = {\n",
    "    'id': \"jepoisso-2\",\n",
    "    'comment_text': \"wow this is nice\",\n",
    "    'toxic': 0,\n",
    "    'severe_toxic': 0,\n",
    "    'obscene': 0,\n",
    "    'threat': 0,\n",
    "    'insult': 0,\n",
    "    'identity_hate': 0\n",
    "}\n",
    "r.json().set(\"unlabeled:2\", Path.root_path(), test_example_2)\n",
    "\n",
    "from redis.commands.json.path import Path\n",
    "test_example_3 = {\n",
    "    'id': \"jepoisso-3\",\n",
    "    'comment_text': \"this is great\",\n",
    "    'toxic': 0,\n",
    "    'severe_toxic': 0,\n",
    "    'obscene': 0,\n",
    "    'threat': 0,\n",
    "    'insult': 0,\n",
    "    'identity_hate': 0\n",
    "}\n",
    "r.json().set(\"unlabeled:3\", Path.root_path(), test_example_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPredicted labels = \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m i: TARGET_CLASSES[i], predicted_labels)))\n\u001b[1;32m      8\u001b[0m unlabeled_dataset \u001b[39m=\u001b[39m RedisDataset(r, \u001b[39m\"\u001b[39m\u001b[39munlabeled:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m unlabeled_dataset \u001b[39m=\u001b[39m to_map_style_dataset(unlabeled_dataset)\n\u001b[1;32m     10\u001b[0m unlabeled_loader \u001b[39m=\u001b[39m DataLoader(unlabeled_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, collate_fn\u001b[39m=\u001b[39mvectorize_batch)\n\u001b[1;32m     12\u001b[0m process_unlabeled(embed_classifier, unlabeled_loader)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchtext/data/functional.py:308\u001b[0m, in \u001b[0;36mto_map_style_dataset\u001b[0;34m(iter_data)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m    306\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[idx]\n\u001b[0;32m--> 308\u001b[0m \u001b[39mreturn\u001b[39;00m _MapStyleDataset(iter_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchtext/data/functional.py:300\u001b[0m, in \u001b[0;36mto_map_style_dataset.<locals>._MapStyleDataset.__init__\u001b[0;34m(self, iter_data)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, iter_data) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# TODO Avoid list issue #1296\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_data)\n",
      "Cell \u001b[0;32mIn[77], line 33\u001b[0m, in \u001b[0;36mRedisDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m()\n\u001b[0;32m---> 33\u001b[0m label \u001b[39m=\u001b[39m get_target_class(obj, key)\n\u001b[1;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m obj[\u001b[39m\"\u001b[39m\u001b[39mcomment_text\u001b[39m\u001b[39m\"\u001b[39m], TARGET_CLASSES\u001b[39m.\u001b[39mindex(label)\n",
      "Cell \u001b[0;32mIn[77], line 13\u001b[0m, in \u001b[0;36mget_target_class\u001b[0;34m(obj, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_target_class\u001b[39m(obj, idx):\n\u001b[0;32m---> 13\u001b[0m     labels \u001b[39m=\u001b[39m {attr: obj[attr] \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m TARGET_CLASSES}\n\u001b[1;32m     14\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m((k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m labels\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m NORMAL_CLASS \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ret\n",
      "Cell \u001b[0;32mIn[77], line 13\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_target_class\u001b[39m(obj, idx):\n\u001b[0;32m---> 13\u001b[0m     labels \u001b[39m=\u001b[39m {attr: obj[attr] \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m TARGET_CLASSES}\n\u001b[1;32m     14\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m((k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m labels\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m NORMAL_CLASS \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ret\n",
      "\u001b[0;31mKeyError\u001b[0m: 'normal'"
     ]
    }
   ],
   "source": [
    "last_idx = len(r.keys(\"labeled:*\"))\n",
    "def process_unlabeled(model, loader):\n",
    "    for X, Y in loader:\n",
    "        preds = model(X)\n",
    "        predicted_labels = F.softmax(preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
    "        print(\"Predicted labels = \", list(map(lambda i: TARGET_CLASSES[i], predicted_labels)))\n",
    "\n",
    "unlabeled_dataset = RedisDataset(r, \"unlabeled:\")\n",
    "unlabeled_dataset = to_map_style_dataset(unlabeled_dataset)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=1, collate_fn=vectorize_batch)\n",
    "\n",
    "process_unlabeled(embed_classifier, unlabeled_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
